import streamlit as st
from router import router, nlu_memory_intent
from lecturefichiersbase import lire_fichier
from llm import repondre_simple, set_runtime_model, get_model

# --- DOIT ÃŠTRE APPELÃ‰ EN PREMIER ---
st.set_page_config(page_title="Alfred v2.1", page_icon="ğŸ¤–", layout="wide")

# =========================================================
# En-tÃªte (affichÃ© avant tout pour Ã©viter toute page "vide")
# =========================================================
st.title("ğŸ¤– Alfred â€” version 2.1 (mÃ©moire persistante + modÃ¨le configurable)")
st.caption(f"âœ… App prÃªte â€” modÃ¨le actif: **{get_model()}**")

# --- MÃ©moire & logs ---
from memoire_alfred import (
    get_memory,
    log_event,
    try_handle_memory_command,
    autosave_heartbeat,
    confirm_delete,
)

# --- SÃ©lecteur de modÃ¨le (optionnel) ---
with st.sidebar:
    st.markdown("### ModÃ¨le LLM")
    model_choice = st.selectbox(
        "SÃ©lection du modÃ¨le",
        options=["gpt-5", "gpt-5-mini", "gpt-4.1", "gpt-4o"],
        index=0,
        help="Change Ã  chaud le modÃ¨le de raisonnement"
    )
    set_runtime_model(model_choice)

# =========================================================
# BoÃ®te de confirmation de suppression (UI)
# =========================================================
def _render_delete_confirmation():
    payload = st.session_state.get("pending_delete")
    if not payload or payload.get("_type") != "confirm_delete":
        return

    item = payload.get("item", {})
    texte = item.get("texte", "")
    loc = payload.get("location")
    cat = payload.get("category")

    msg = f"Confirmer la suppression du souvenir :\n\n> **{texte}**"
    if loc == "categorie" and cat:
        msg += f"\n\n(CatÃ©gorie : **{cat}**)"

    st.warning(msg)
    c1, c2 = st.columns(2)
    if c1.button("âœ… Oui, supprimer"):
        res = confirm_delete(payload)
        st.success(res)
        st.session_state["pending_delete"] = None
    if c2.button("âŒ Annuler"):
        st.info("Suppression annulÃ©e.")
        st.session_state["pending_delete"] = None

# =========================================================
# Corps de l'app
# =========================================================

# Heartbeat autosave (RAM -> Drive pÃ©riodique)
autosave_heartbeat()

# Historique de chat en session
if "messages" not in st.session_state:
    st.session_state.messages = []

# Afficher l'historique
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        if isinstance(m["content"], str) and ("ğŸ“" in m["content"] or "ğŸ“„" in m["content"]):
            st.text(m["content"])
        else:
            st.markdown(m["content"])

# Zone de saisie utilisateur (footer)
prompt = st.chat_input("Parle Ã  Alfredâ€¦")

# Uploader (dans le corps)
fichier = st.file_uploader("ğŸ“ Joindre un fichier (optionnel)", type=None)

# Rendre la boÃ®te de confirmation si besoin
_render_delete_confirmation()

if prompt:
    # Afficher le message utilisateur dans le chat
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ã‰tape 1 : intents mÃ©moire (ajout, rappel, suppression, importâ€¦)
    handled, payload = try_handle_memory_command(prompt)
    if handled:
        # Cas 1 : message simple (ex: "ğŸ§  Câ€™est notÃ©...")
        if isinstance(payload, str):
            st.success(payload)
            st.stop()

        # Cas 2 : rappel (liste)
        if isinstance(payload, list):
            if not payload:
                st.info("Aucun souvenir correspondant.")
                st.stop()
            st.markdown("### ğŸ§  Souvenirs")
            for s in payload:
                st.write(f"- [{s['date']}] {s['texte']}")
            st.stop()

        # Cas 3 : suppression â€” poser le payload puis relancer pour afficher les boutons
        elif isinstance(payload, dict) and payload.get("_type") == "confirm_delete":
            st.session_state["pending_delete"] = payload
            st.rerun()  # affiche immÃ©diatement la boÃ®te Oui/Non

    # Ã‰tape 2 : Routage Drive & co (briques spÃ©cialisÃ©es)
    reponse = router(prompt)
    if reponse is None:
        # Ã‰tape 3 : Appel LLM "par dÃ©faut"
        if fichier:
            contenu = lire_fichier(fichier)
            prompt_final = f"{prompt}\n\nVoici le contenu du fichier :\n{contenu}"
        else:
            prompt_final = prompt

        # ğŸ” Appel au LLM via couche gÃ©nÃ©rique (modÃ¨le dÃ©fini par lâ€™UI/ENV)
        reponse = repondre_simple(prompt_final)

    # Affichage de la rÃ©ponse
    st.session_state.messages.append({"role": "assistant", "content": reponse})
    with st.chat_message("assistant"):
        if isinstance(reponse, str) and ("ğŸ“" in reponse or "ğŸ“„" in reponse):
            st.text(reponse)
        else:
            st.markdown(reponse)
